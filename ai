import streamlit as st
import re
from datetime import datetime, timedelta
from collections import defaultdict
import pandas as pd

# Optional AI (safe)
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except:
    SKLEARN_AVAILABLE = False

# ================= CONFIG =================
IGNORE_PHRASES = ["<media omitted>", "this message was deleted"]

RESOLVED_KEYWORDS = [
    "resolved", "issue resolved", "issue solved",
    "done", "problem solved"
]

PROJECT_KEYWORDS = {
    "MNM": ["mnm"],
    "Bhavnagar": ["bhavnagar"],
    "Umarsar": ["umarsar"]
}

NEGATIVE_WORDS = [
    "error", "not generated", "unable", "failed",
    "issue", "problem", "zero", "pending", "not created","no"
]

# ================= NORMALIZATION =================
def normalize_text(text):
    t = text.lower()
    # ‚úÖ KEEP DEVILERY LOGIC EXACTLY SAME
    for wrong in ["devilery", "devilvery", "delivary"]:
        t = t.replace(wrong, "delivery")
    return t

# ================= CLASSIFICATION =================
def detect_project(text):
    t = normalize_text(text)
    for project, keys in PROJECT_KEYWORDS.items():
        if any(k in t for k in keys):
            return project
    return "Unknown"

def is_resolved(text):
    return any(k in normalize_text(text) for k in RESOLVED_KEYWORDS)

def has_negative(text):
    t = normalize_text(text)
    return any(n in t for n in NEGATIVE_WORDS)

def categorize(text):
    t = normalize_text(text)

    # ‚úÖ DELIVERY FIRST (preserves devilery count)
    if "delivery" in t:
        return "Delivery"

    # üî¥ NEGATIVE (only if not delivery)
    if has_negative(text):
        return "Negative"

    if "network" in t or "slow" in t:
        return "Network"
    if "invoice" in t or "einvoice" in t:
        return "Invoice"
    if "weight" in t or "wb" in t or "tare" in t or "gross" in t:
        return "Weighbridge"
    if "token" in t:
        return "Token"

    return None  # ‚ùå No Others

# ================= PARSER =================
def parse_chat(lines):
    complaints = []
    six_months_ago = datetime.now() - timedelta(days=180)

    pattern = re.compile(
        r"(\d{1,2}/\d{1,2}/\d{2}),\s(\d{1,2}:\d{2})\s?(AM|PM)\s-\s([^:]+):\s(.+)",
        re.IGNORECASE
    )

    for line in lines:
        line = line.replace("\u202f", " ").replace("\u00a0", " ")

        if any(p in line.lower() for p in IGNORE_PHRASES):
            continue

        m = pattern.match(line)
        if not m:
            continue

        date_str, time_str, ampm, sender, message = m.groups()

        try:
            ts = datetime.strptime(
                f"{date_str} {time_str} {ampm}",
                "%m/%d/%y %I:%M %p"
            )
        except:
            continue

        # ‚è≥ ONLY LAST 6 MONTHS
        if ts < six_months_ago:
            continue

        category = categorize(message)
        if not category:
            continue

        complaints.append({
            "time": ts,
            "month": ts.strftime("%b %Y"),
            "project": detect_project(message),
            "category": category,
            "resolved": is_resolved(message),
            "message": message
        })

    return complaints

# ================= HELPERS =================
def filter_days(df, days):
    return df[df["time"] >= datetime.now() - timedelta(days=days)]

def count_table(series):
    return series.value_counts().to_frame("Count")

def resolved_table(df):
    return pd.DataFrame(
        {"Count": [df["resolved"].sum(), len(df) - df["resolved"].sum()]},
        index=["Resolved", "Pending"]
    )

def monthly_trend(df):
    return df.groupby("month").size().to_frame("Complaints")

# ================= AI =================
def cluster_complaints(messages, k):
    vec = TfidfVectorizer(stop_words="english", max_features=500)
    X = vec.fit_transform(messages)
    model = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels = model.fit_predict(X)

    clusters = defaultdict(list)
    for msg, lab in zip(messages, labels):
        clusters[lab].append(msg)
    return clusters

# ================= UI =================
st.set_page_config(page_title="WhatsApp IT Complaint Analyzer")

st.title("üìä WhatsApp IT Complaint Analyzer")
st.write(
    "üìÖ **Last 1 Month & Last 6 Months** | "
    "‚úÖ Devilery logic preserved | "
    "üö® Negative as main category | "
    "üìã Tables + üìä Charts"
)

uploaded_file = st.file_uploader("Upload WhatsApp Chat (.txt)", type=["txt"])

if uploaded_file:
    lines = uploaded_file.read().decode("utf-8", errors="ignore").splitlines()
    data = parse_chat(lines)

    if not data:
        st.warning("‚ö†Ô∏è No IT complaints found.")
    else:
        df = pd.DataFrame(data)

        df_1m = filter_days(df, 30)
        df_6m = df.copy()

        def render_section(title, dfx):
            st.header(title)

            st.subheader("Category-wise")
            cat = count_table(dfx["category"])
            st.dataframe(cat)
            st.bar_chart(cat)

            st.subheader("Project-wise")
            proj = count_table(dfx["project"])
            st.dataframe(proj)
            st.bar_chart(proj)

            st.subheader("Resolved vs Pending")
            res = resolved_table(dfx)
            st.dataframe(res)
            st.bar_chart(res)

            st.subheader("Monthly Trend")
            trend = monthly_trend(dfx)
            st.dataframe(trend)
            st.line_chart(trend)

        render_section("üìÖ Last 1 Month", df_1m)
        render_section("üìÜ Last 6 Months", df_6m)

        # -------- AI CLUSTERING --------
        st.header("ü§ñ AI-based Issue Clustering (Last 6 Months)")

        if SKLEARN_AVAILABLE and len(df_6m) >= 5:
            k = st.slider("Number of clusters", 2, 6, 4)
            clusters = cluster_complaints(df_6m["message"].tolist(), k)

            for cid, msgs in clusters.items():
                st.subheader(f"Cluster {cid + 1}")
                st.dataframe(pd.DataFrame({"Sample Issues": msgs[:10]}))
        else:
            st.info("Not enough data or AI library missing")

        st.success("‚úÖ Analysis completed successfully")

st.caption(
    "‚úî Devilery ‚Üí Delivery preserved ‚Ä¢ "
    "‚úî Negative added safely ‚Ä¢ "
    "‚úî 1M & 6M ‚Ä¢ "
    "‚úî Production ready"
)
